EXP_NAME: RoBERTa_LSTM
SEED: 223

MODE:
    do_train: True
    do_test: False
    
DATASET:
    name: BERT_LSTM
    data_path: ../data/Part1 # news article directory
    saved_data_path: ../data-direct/tfidf_title_category_select/RoBERTa_LSTM
    PARAMETERS:
        max_word_len: 512
        use_cat: True
    direct_path: ../data-direct/tfidf_title_category_select

TOKENIZER:
    name: RoBERTa
    pretrained_model_name_or_path: klue/roberta-base
    
MODEL:
    modelname: bert_lstm
    PARAMETERS:
        pretrained_name: 'klue/roberta-base'
        num_classes: 2
    CHECKPOINT:
        checkpoint_path: null
    Exp_Params:
        hidden_size: 256
        num_layers: 1
    
TRAIN:
    batch_size: 8
    num_training_steps: 10000
    accumulation_steps: 1
    num_workers: 12
    use_wandb: False

LOG:
    log_interval: 1
    eval_interval: 1000

OPTIMIZER:
    lr: 0.00001
    weight_decay: 0.0005

SCHEDULER:
    warmup_ratio: 0.1
    use_scheduler: True

RESULT:
    savedir: ./saved_model-direct/tfidf_title_category_select